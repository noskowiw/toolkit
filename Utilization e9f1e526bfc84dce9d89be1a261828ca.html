<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Utilization</title><link rel="stylesheet" href="style.css"></head><body><article id="e9f1e526-bfc8-4dce-9d89-be1a261828ca" class="page sans"><header><p class="page-description"></p></header><div class="page-body"><p id="df114444-5653-4964-bc60-a2be25a1cd84" class="">date:</p><p id="091946e0-2211-446d-a3f6-ed8705190f44" class="">author: Wojciech Noskowiak</p><h2 id="169051d6-38be-428e-ae7f-8a02d3d3004a" class="">in short:</h2><ul id="ea23a30f-db1b-4b5d-8cd5-bb3a782863f9" class="bulleted-list"><li style="list-style-type:disc">even an idling virtual machine is responsible for some amount of energy consumption, leaving unutilized resources should be avoided at all cost </li></ul><ul id="1cec1cfa-f393-46d9-bad2-9ade935012fa" class="bulleted-list"><li style="list-style-type:disc">Underutilizing resources doesnâ€™t allow them to reach their full theoretical energy efficiency. When choosing what hardware to use when deploying your application always consider the amount of computing power it requires and choose the appropriate instance type accordingly </li></ul><p id="3257ee67-5b58-40d0-bd76-e1c97ce919d7" class="">Provisioning resources on demand is the main advantage of cloud computing, and a big part of why it can be a more sustainable option for deploying and developing applications. This freedom  however makes it very easy to ignore utilization inefficiencies.  leaving provisioned resources idle or Performing calculations that only consume fractions of their capacity is a common occurrence in cloud architectures, and is responsible for a significant reduction in their efficiency </p><p id="7fb3e601-a4b3-4ca5-8cf7-f426ba4dc4cc" class="">According to a study published by Google researchers, server energy consumption is directly proportional to CPU utilization. The relationship they discovered can be visualized through the following plot:</p><p id="df1f98d1-24b2-45d1-9702-a3242f6d1aad" class="">
</p><figure id="96bfd81d-bde4-4471-ae46-81ca4583c350" class="image"><a href="Utilization%20e9f1e526bfc84dce9d89be1a261828ca/Group_3.svg"><img style="width:528px" src="Utilization%20e9f1e526bfc84dce9d89be1a261828ca/Group_3.svg"/></a></figure><p id="aa0a99dc-b3aa-4856-8a53-8aaa690bf8f2" class="">source: <a href="https://dl.acm.org/doi/pdf/10.1145/1250662.1250665">1250662.1250665 (acm.org)</a></p><p id="6236624b-81f0-4f4b-81ee-bb99c809cf9e" class="">Based on this relationship, two main conclusions can be drawn:</p><ul id="a56e4088-139f-4351-aa39-952121120874" class="bulleted-list"><li style="list-style-type:disc">Under provisioned resources are inherently less energy efficient. Every computer consumes some power even when not performing calculations.
The servers are most energy efficient when utilized to their fullest potential.</li></ul><ul id="8432e919-3edb-4180-a459-fae6e1039c34" class="bulleted-list"><li style="list-style-type:disc">even and idling virtual machine is responsible for a not insignificant amount of electricity consumption. Although the graph in question referrers to an energy consumption of a whole physical server, even a small virtual machine  provisioned on it requires a fraction of its resources to be reserved for its own use. keeping those fractional resources idle prevents the server from reaching it&#x27;s full capacity, making it less energy efficient.</li></ul><p id="6663a616-3056-4309-b246-29013c216608" class="">
</p></div></article></body></html>