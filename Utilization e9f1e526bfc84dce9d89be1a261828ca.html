<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Utilization</title><link href="style.css" rel="stylesheet"/></head><body><article class="page sans" id="e9f1e526-bfc8-4dce-9d89-be1a261828ca"><header><figure class="image" id="a1dd3af8-a7ba-4f6c-9d16-1a70dfed2a13"><img src="Group_22.svg" style="width:240px"/></figure><h1 class="page-title">Utilization</h1><p class="page-description"></p></header><div class="page-body"><p class="" id="df114444-5653-4964-bc60-a2be25a1cd84">date:</p><p class="" id="091946e0-2211-446d-a3f6-ed8705190f44">author: Wojciech Noskowiak</p><h2 class="" id="169051d6-38be-428e-ae7f-8a02d3d3004a">In short:</h2><ul class="bulleted-list" id="ea23a30f-db1b-4b5d-8cd5-bb3a782863f9"><li style="list-style-type:disc">Even an idling virtual machine is responsible for some amount of energy consumption, leaving resources unutilized should be avoided at all cost </li></ul><ul class="bulleted-list" id="1cec1cfa-f393-46d9-bad2-9ade935012fa"><li style="list-style-type:disc">Underutilizing resources does not allow them to reach their full theoretical energy efficiency. When choosing what hardware to use when deploying your application always consider the amount of computing power it requires and choose the appropriate instance type accordingly </li></ul><p class="" id="3257ee67-5b58-40d0-bd76-e1c97ce919d7">Provisioning resources on demand is the main advantage of cloud computing, and a big part of why it can be a more sustainable option for deploying and developing applications. This freedom,  however, makes it very easy to ignore utilization inefficiencies. Leaving provisioned resources idle or performing calculations that only consume a fraction of their capacity is a common occurrence in cloud architectures, and is responsible for a significant reduction in their efficiency.</p><p class="" id="7fb3e601-a4b3-4ca5-8cf7-f426ba4dc4cc">According to a study published by Google researchers, server energy consumption is directly proportional to CPU utilization. The relationship they discovered can be visualized through the following plot:</p><p class="" id="df1f98d1-24b2-45d1-9702-a3242f6d1aad">
</p><figure class="image" id="96bfd81d-bde4-4471-ae46-81ca4583c350"><img src="Group_3.svg" style="width:528px"/></figure><p class="" id="aa0a99dc-b3aa-4856-8a53-8aaa690bf8f2">source: <a href="https://dl.acm.org/doi/pdf/10.1145/1250662.1250665">1250662.1250665 (acm.org)</a></p><p class="" id="6236624b-81f0-4f4b-81ee-bb99c809cf9e">Based on this relationship, two main conclusions can be drawn:</p><ul class="bulleted-list" id="a56e4088-139f-4351-aa39-952121120874"><li style="list-style-type:disc">Under-provisioned resources are inherently less energy efficient. Every computer consumes some power even when not performing calculations. The servers are most energy efficient when utilized to their fullest potential.</li></ul><ul class="bulleted-list" id="8432e919-3edb-4180-a459-fae6e1039c34"><li style="list-style-type:disc">Even and idling virtual machine is responsible for a significant amount of electricity consumption. Although the graph in question referrers to the energy consumption of a whole physical server, even a small virtual machine provisioned on it requires a fraction of its resources to be reserved for its own use. Keeping those fractional resources idle prevents the server from reaching it's full capacity, making it less energy efficient.</li></ul><p class="" id="6663a616-3056-4309-b246-29013c216608">
</p></div></article></body></html>