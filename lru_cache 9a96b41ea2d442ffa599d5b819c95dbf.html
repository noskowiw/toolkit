<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>lru_cache</title><link href="style.css" rel="stylesheet"/></head><body><article class="page sans" id="9a96b41e-a2d4-42ff-a599-d5b819c95dbf"><header><figure class="image" id="9d8801ec-75ce-4e86-94e2-89edf656e861"><img src="Group_62.svg" style="width:240px"/></figure><h1 class="page-title">lru_cache</h1><p class="page-description"></p></header><div class="page-body"><p class="" id="e80e0a7f-26ed-400f-9044-707354d694d0">date:</p><p class="" id="943537cc-76b3-47a4-80d9-da4d97428eac">author: Wojciech Noskowiak</p><p class="" id="04b35053-2790-4a2d-8dd9-3f58356a2dda">
</p><p class="" id="12e4b420-5a95-46db-a6a0-1d0ea0a24cfb">The <code>lru_cache</code> is a Python library that provides a caching mechanism for functions. It is a decorator that can be applied to a function to cache its return values. The decorator works by caching the results of the function for a certain number of calls, and then discarding the least recently used result when the cache is full. This can be useful for functions that are computationally expensive or time-consuming to execute.</p><p class="" id="211b2b60-a4c7-4fd7-a4e8-94f87843e76a">To use <code>lru_cache</code> import it and apply it as a decorator to the function you want to cache. The decorator takes an optional argument <code>maxsize</code>, which specifies the maximum number of results to cache. If <code>maxsize</code> is not specified, the cache will be unbounded.</p><p class="" id="9cb01105-136f-4343-b93a-a413967eaa1b">The <code>lru_cache</code> decorator is part of the Python standard library since version 3.2. It is a convenient and easy-to-use tool for optimizing the performance of Python functions that are frequently called with the same arguments.</p><p class="" id="f8630c88-6371-49b9-b0a0-9c01ad78db5a">consider a very simple recursive implementation of the Fibonacci sequence:</p><pre class="code" id="f92f509a-36ac-47e7-89e6-0f0f32adf7d9"><code>def fib(n):
    if n &lt; 2:
        return n
    return fib(n-1) + fib(n-2)</code></pre><p class="" id="ff42ad2f-13ac-49c4-a34c-aa4b66f9712e">applying caching to this function is as easy as applying the decorator:</p><pre class="code" id="349ad65a-86c1-4572-a366-84cafc3f937f"><code>from functools import lru_cache

@lru_cache(maxsize = 128)
def fib(n):
    if n &lt; 2:
        return n
    return fib(n-1) + fib(n-2)</code></pre><p class="" id="71792343-9d6d-4552-851a-cd6c68cff9bd">In the case of this function, the execution time for calculating the 30th element of the Fibonacci sequence without caching was 0.44482s. With caching, it was 0.0000283s. That constitutes a performance increase of more than 15000 times.</p><p class="" id="f9a50173-d968-4b14-93bb-60a06698f13e">I should go without saying that this method of caching is only applicable for functions who’s output does not change with time.</p><p class="" id="bc8d1f10-b8b8-4c43-8fff-7e94d403c934">
</p><p class="" id="6b44cc72-25d3-4314-a073-d64501368115">documentation: <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">https://docs.python.org/3/library/functools.html#functools.lru_cache</a></p><p class="" id="1f25485b-d4b6-4bb0-8702-00e9841ef06a">
</p><p class="" id="40ffa2b3-c21e-4051-9ca0-bbf886fd33c5">sources : </p><ul class="bulleted-list" id="37470438-644e-458a-ad9c-64ff773ede29"><li style="list-style-type:disc"><a href="https://www.geeksforgeeks.org/python-functools-lru_cache/">https://www.geeksforgeeks.org/python-functools-lru_cache/</a></li></ul><ul class="bulleted-list" id="f7e9695c-36ee-4947-a517-e13ea7489018"><li style="list-style-type:disc"><a href="https://docs.python.org/3/library/functools.html#functools.lru_cache">https://docs.python.org/3/library/functools.html#functools.lru_cache</a></li></ul><p class="" id="e2c34f75-d84d-4243-8115-754ea207b7bc">
</p></div></article></body></html>